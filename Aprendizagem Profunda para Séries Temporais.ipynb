{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Aprendizagem Profunda para Séries Temporais</h1>\n",
    "<p align=\"center\"><img src= https://media-exp1.licdn.com/dms/image/C4E12AQFdokK0C2s_Jg/article-cover_image-shrink_720_1280/0/1532552837990?e=1652918400&v=beta&t=mXqTtqQOuLvkZMioNLU8kkxXRcm4ogDbF6PAWJVKHE0 heigth=350 width=600></p>\n",
    "\n",
    "<p align=\"justify\">O aprendizado profundo é um subcampo do aprendizado de máquina preocupado com algoritmos relacionados às redes neurais. Redes neurais, ou, mais precisamente, redes neurais artificiais(RNAs) receberam esse nome por causa da associação com os neurônios biológicos em formato de redes no cérebro humano.</p>\n",
    "<p align='justify'>Nos últimos anos, o aprendizado profundo vem aprimorando o estado da arte em muitos campos de aplicação. Isso vale para conjuntos de dados não estruturados, como texto, imagens, vídeo e áudio. No entanto, os conjuntos de dados tabulares e séries temporais até agora se mostraram menos passíveis de aprendizado profundo.</p>\n",
    "\n",
    "<p align=\"justify\">Entre as contribuições que o aprendizado profundo foi capaz de trazer para séries temporais estão o <i>Data Augmentation</i> (Aumento de Dados), o <i>Transfer Learning</i> (Aprendizado por Transferência), as previsões de séries temporais de sequência longa e Geração de dados com Redes Adversariais Generativas (GANs). No entanto, é muito recente que as abordagens de aprendizagem profunda tornaram-se competitivas em relação às tarefas de previsão, classificação e regressão.</p>\n",
    "\n",
    "<p align=\"justify\">Nos últimos anos, houve uma proliferação de redes neurais profundas, com melhorias em vários domínios de aplicação, em particular, as imagens, o processamento de linguagem e som. A vantagem potencial dos modelos de aprendizado profundo é que eles podem ser muito mais precisos do que outros tipos de modelos, dominando as áreas como visão, som e Processamento de Linguagem Natural (PNL).</p>\n",
    "\n",
    "<p align=\"justify\">Muitos algoritmos de aprendizado profundo foram aplicados mais recentemente para as séries temporais, tanto com as séries temporais univariadas e como as multivariadas. As arquiteturas de modelo abrangem redes neurais recorrentes (RNNs), as <i>Long short-term Memory</i> (LTSM) e os modelos transformador (<i>Transformer</i>) e convolucional, ou diferentes tipos de codificadores automáticos.</p>\n",
    "\n",
    "<p align=\"justify\">É dificil superar as abordagens de linha de base, como o Vizinho Mais Próximo com <i>Dynamic Time Warping</i> (DTW) e, em seguida,abordagens de última geração. O modelo mais competitivo, em termos de desempenho, é o HIVE-COTE (Coletivo de Votos Hierárquicos de Ensembles Baseados em Transformação), que consiste em um conjunto de modelos de aprendizado de máquina  – muito caros em termos de recursos, devido ao número de cálculos e o longo tempo de execução.</p>\n",
    "\n",
    "<p align=\"justify\">Existem alguns modelos que são extremamente bons para Aprendizado Profundo nas Séries Temporais:</p>\n",
    "<li><a href=https://github.com/hfawaz/dl-4-tsc>dl-4-ts</a> pertencente às bibliotecas do TensorFlow e Keras.</li>\n",
    "<li><a href=https://www.sktime.org/en/stable/>Sktime-DL</a> pertencente às bibliotecas do TensorFlow e Keras.</li>\n",
    "<li><a href=https://ts.gluon.ai/>Gluon-TS</a> pertencente à biblioteca do MXNET.</li>\n",
    "<li><a href=https://pytorch-forecasting.readthedocs.io/en/stable/>Pytorch Forecasting</a> pertencente à biblioteca do Pytorch Lightning.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Autoencoders</h2>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8bbe703e4409461e5c1796f0c401e26e62f32801f1a5b19455b89c31c613fbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
